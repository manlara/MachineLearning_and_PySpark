
* Start with 22.1.05 (Day 1 Activity 5)

* What is Spark?
Apache Spark is a unified analytics engine for large-scale data processing. It lets you write applications in Java, Scala, Python, R, and SQL and runs on Hadoop, stand-alone, or in the cloud (and many other platforms). Spark can be 100 times faster than Hadoop. Spark can do
	* Machine Learning
	* Manage streaming data
    * accessing/manipulating data in a sql-like way
	* Graph layer for querying data as though it was a graph database

* Spark ecosystem
https://www.kdnuggets.com/wp-content/uploads/spark-ecosystem.jpg

* Spark session
https://abhishekbaranwal10.files.wordpress.com/2018/09/introduction-to-apache-spark-20-12-638.jpg?resize=638%2C479

* Main PySpark documentation
https://spark.apache.org/docs/latest/api/python/pyspark.sql.html


* Things we'll do

    1) PySpark data maipulations

    2) Connect to Local Postgres DB

    3) Connect to Local MongoDB