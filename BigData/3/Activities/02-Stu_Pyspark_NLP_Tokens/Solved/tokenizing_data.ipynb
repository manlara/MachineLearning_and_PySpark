{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Additional Python Libraries\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding environment variable `PYSPARK_SUBMIT_ARGS`\n",
      "--packages com.databricks:spark-csv_2.11:1.5.0 pyspark-shell\n"
     ]
    }
   ],
   "source": [
    "from spark_libs import spark_submit\n",
    "packages = [\"com.databricks:spark-csv_2.11:1.5.0\"]\n",
    "spark_submit(packages=packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.ml.feature import RegexTokenizer, Tokenizer\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark import SparkFiles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get or create Spark session\n",
    "\n",
    "app_name = \"tokenizing-data\"\n",
    "spark = SparkSession.builder.appName(app_name).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Poem: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read in data from S3 Buckets\n",
    "url =\"https://s3.amazonaws.com/dataviz-curriculum/day_2/data.csv\"\n",
    "spark.sparkContext.addFile(url)\n",
    "\n",
    "df = spark.read \\\n",
    "    .format(\"com.databricks.spark.csv\") \\\n",
    "    .options(header='true', inferSchema=\"true\") \\\n",
    "    .load(SparkFiles.get(\"data.csv\"))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Poem|\n",
      "+--------------------+\n",
      "|This Autumn midnight|\n",
      "|Orion’s at my window|\n",
      "|shouting for his ...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize DataFrame\n",
    "tokened = Tokenizer(inputCol=\"Poem\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                Poem|               words|\n",
      "+--------------------+--------------------+\n",
      "|This Autumn midnight|[this, autumn, mi...|\n",
      "|Orion’s at my window|[orion’s, at, my,...|\n",
      "|shouting for his ...|[shouting, for, h...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform DataFrame\n",
    "tokenized = tokened.transform(df)\n",
    "tokenized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Function to count vowels\n",
    "@F.udf(returnType=IntegerType())\n",
    "def vowel_counter(words):\n",
    "    vowel_count = 0\n",
    "\n",
    "    for word in words:\n",
    "        for letter in word:\n",
    "            if letter in ('a', 'e', 'i', 'o', 'u'):\n",
    "                vowel_count += 1\n",
    "\n",
    "    return vowel_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a user defined function\n",
    "# non-decorator approach\n",
    "# count_vowels = udf(vowel_counter, IntegerType())\n",
    "# count_vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+--------------------------+------+\n",
      "|Poem                 |words                     |vowels|\n",
      "+---------------------+--------------------------+------+\n",
      "|This Autumn midnight |[this, autumn, midnight]  |6     |\n",
      "|Orion’s at my window |[orion’s, at, my, window] |6     |\n",
      "|shouting for his dog.|[shouting, for, his, dog.]|6     |\n",
      "+---------------------+--------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create new DataFrame with the udf\n",
    "tokenized \\\n",
    "    .select(\"Poem\", \"words\") \\\n",
    "    .withColumn(\"vowels\", vowel_counter(F.col(\"words\"))) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
