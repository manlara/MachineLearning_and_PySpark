{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Additional Python Libraries\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding environment variable `PYSPARK_SUBMIT_ARGS`\n",
      "--packages com.databricks:spark-csv_2.11:1.5.0 pyspark-shell\n"
     ]
    }
   ],
   "source": [
    "from spark_libs import spark_submit\n",
    "packages = [\"com.databricks:spark-csv_2.11:1.5.0\"]\n",
    "spark_submit(packages=packages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import DataFrame\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.sql.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get or create Spark session\n",
    "\n",
    "app_name = \"spark-udf\"\n",
    "spark = SparkSession.builder.appName(app_name).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|       Nursery Rhyme|\n",
      "+---+--------------------+\n",
      "|  0|Mary had a little...|\n",
      "|  1|It's fleece was w...|\n",
      "|  2|And everywhere Ma...|\n",
      "|  3|The lamb was sure...|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe = spark.createDataFrame([\n",
    "    (0, \"Mary had a little lamb\"),\n",
    "    (1, \"It's fleece was white as snow\"),\n",
    "    (2, \"And everywhere Mary went\"),\n",
    "    (3, \"The lamb was sure to go\")\n",
    "], [\"id\", \"Nursery Rhyme\"])\n",
    "dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to count occurrences of Mary\n",
    "def mary_counter(rhyme):\n",
    "    counter = 0\n",
    "    for word in rhyme.split(\" \"):\n",
    "        if word.lower() == \"mary\":\n",
    "            counter += 1\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------+\n",
      "| id|       Nursery Rhyme|mary count|\n",
      "+---+--------------------+----------+\n",
      "|  0|Mary had a little...|         1|\n",
      "|  1|It's fleece was w...|         0|\n",
      "|  2|And everywhere Ma...|         1|\n",
      "|  3|The lamb was sure...|         0|\n",
      "+---+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mary_udf = F.udf(mary_counter, IntegerType())\n",
    "dataframe.withColumn(\"mary count\", mary_udf(\"Nursery Rhyme\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function udf in module pyspark.sql.functions:\n",
      "\n",
      "udf(f=None, returnType=StringType)\n",
      "    Creates a user defined function (UDF).\n",
      "    \n",
      "    .. note:: The user-defined functions are considered deterministic by default. Due to\n",
      "        optimization, duplicate invocations may be eliminated or the function may even be invoked\n",
      "        more times than it is present in the query. If your function is not deterministic, call\n",
      "        `asNondeterministic` on the user defined function. E.g.:\n",
      "    \n",
      "    >>> from pyspark.sql.types import IntegerType\n",
      "    >>> import random\n",
      "    >>> random_udf = udf(lambda: int(random.random() * 100), IntegerType()).asNondeterministic()\n",
      "    \n",
      "    .. note:: The user-defined functions do not support conditional expressions or short circuiting\n",
      "        in boolean expressions and it ends up with being executed all internally. If the functions\n",
      "        can fail on special rows, the workaround is to incorporate the condition into the functions.\n",
      "    \n",
      "    .. note:: The user-defined functions do not take keyword arguments on the calling side.\n",
      "    \n",
      "    :param f: python function if used as a standalone function\n",
      "    :param returnType: the return type of the user-defined function. The value can be either a\n",
      "        :class:`pyspark.sql.types.DataType` object or a DDL-formatted type string.\n",
      "    \n",
      "    >>> from pyspark.sql.types import IntegerType\n",
      "    >>> slen = udf(lambda s: len(s), IntegerType())\n",
      "    >>> @udf\n",
      "    ... def to_upper(s):\n",
      "    ...     if s is not None:\n",
      "    ...         return s.upper()\n",
      "    ...\n",
      "    >>> @udf(returnType=IntegerType())\n",
      "    ... def add_one(x):\n",
      "    ...     if x is not None:\n",
      "    ...         return x + 1\n",
      "    ...\n",
      "    >>> df = spark.createDataFrame([(1, \"John Doe\", 21)], (\"id\", \"name\", \"age\"))\n",
      "    >>> df.select(slen(\"name\").alias(\"slen(name)\"), to_upper(\"name\"), add_one(\"age\")).show()\n",
      "    +----------+--------------+------------+\n",
      "    |slen(name)|to_upper(name)|add_one(age)|\n",
      "    +----------+--------------+------------+\n",
      "    |         8|      JOHN DOE|          22|\n",
      "    +----------+--------------+------------+\n",
      "    \n",
      "    .. versionadded:: 1.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decorators offer a more concise method\n",
    "# Documentation: https://spark.apache.org/docs/latest/api/python/_modules/pyspark/sql/functions.html#udf)\n",
    "help(F.udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------+\n",
      "| id|       Nursery Rhyme|mary count|\n",
      "+---+--------------------+----------+\n",
      "|  0|Mary had a little...|         1|\n",
      "|  1|It's fleece was w...|         0|\n",
      "|  2|And everywhere Ma...|         1|\n",
      "|  3|The lamb was sure...|         0|\n",
      "+---+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@F.udf(returnType=IntegerType())\n",
    "def mary_counter(rhyme):\n",
    "    counter = 0\n",
    "    for word in rhyme.split(\" \"):\n",
    "        if word.lower() == \"mary\":\n",
    "            counter += 1\n",
    "    return counter\n",
    "dataframe.withColumn(\"mary count\", mary_counter(\"Nursery Rhyme\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tokenizer_c9dc6e547fa3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize word\n",
    "tokenizer = Tokenizer(inputCol=\"Nursery Rhyme\", outputCol=\"words\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@F.udf(returnType=IntegerType())\n",
    "# Create a function to return the length of a list\n",
    "def word_list_length(word_list):\n",
    "    return len(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+------------------------------------+------+\n",
      "|Nursery Rhyme                |words                               |tokens|\n",
      "+-----------------------------+------------------------------------+------+\n",
      "|Mary had a little lamb       |[mary, had, a, little, lamb]        |5     |\n",
      "|It's fleece was white as snow|[it's, fleece, was, white, as, snow]|6     |\n",
      "|And everywhere Mary went     |[and, everywhere, mary, went]       |4     |\n",
      "|The lamb was sure to go      |[the, lamb, was, sure, to, go]      |6     |\n",
      "+-----------------------------+------------------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform DataFrame\n",
    "tokenized = tokenizer.transform(dataframe)\n",
    "\n",
    "# Select the needed columns and don't truncate results\n",
    "tokenized.select(\"Nursery Rhyme\", \"words\")\\\n",
    "    .withColumn(\"tokens\", word_list_length(F.col(\"words\"))).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+------------------------------------+------+\n",
      "|Nursery Rhyme                |words                               |tokens|\n",
      "+-----------------------------+------------------------------------+------+\n",
      "|Mary had a little lamb       |[mary, had, a, little, lamb]        |5     |\n",
      "|It's fleece was white as snow|[it's, fleece, was, white, as, snow]|6     |\n",
      "|And everywhere Mary went     |[and, everywhere, mary, went]       |4     |\n",
      "|The lamb was sure to go      |[the, lamb, was, sure, to, go]      |6     |\n",
      "+-----------------------------+------------------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# User-Defined Functions are not optimized\n",
    "# Always try using the built-in Spark functions before writing your own\n",
    "# pysaprl.sql.functions.size also counts length of list\n",
    "tokenized.select(\"Nursery Rhyme\", \"words\")\\\n",
    "    .withColumn(\"tokens\", F.size(\"words\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
