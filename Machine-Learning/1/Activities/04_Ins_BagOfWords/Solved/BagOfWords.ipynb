{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "\n",
    "One way to understand the context of some statement is to analyze just the word frequencies. Their is a drawback to this approach, namely, language encodes meaning based on order of words. Still, this approach can be effective with the right dataset and goal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>Crust is not good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      class                                               text\n",
       "0  positive                           Wow... Loved this place.\n",
       "1  negative                                 Crust is not good.\n",
       "2  negative          Not tasty and the texture was just nasty.\n",
       "3  positive  Stopped by during the late May bank holiday of...\n",
       "4  positive  The selection on the menu was great and so wer..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "fname = \"../Resources/yelp_reviews.csv\"\n",
    "data = pd.read_csv(fname)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting text to word frequencies\n",
    "\n",
    "Removing filler words will help the model since these words rarely add meaning. Text is converted to a vector of numbers where the value represents the frequency of a word and the position in the vector distinguishes each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of frequencies:\n",
      " [2, 2, 2, 1, 2, 2, 2, 1, 1, 1]\n",
      "Corresponding words:\n",
      " ['Peter', 'Piper', 'picked', 'a', 'peck', 'of', 'pickled', 'peppers;', 'A', 'peppers']\n"
     ]
    }
   ],
   "source": [
    "# convert text to word frequencies\n",
    "from collections import Counter\n",
    "text = \"Peter Piper picked a peck of pickled peppers; A peck of pickled peppers Peter Piper picked\"\n",
    "word_frequency = Counter(text.split())\n",
    "print(\"Vector of frequencies:\\n {}\".format(list(word_frequency.values())))\n",
    "print(\"Corresponding words:\\n {}\".format(list(word_frequency.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peter',\n",
       " 'piper',\n",
       " 'pick',\n",
       " 'peck',\n",
       " 'pickl',\n",
       " 'pepper',\n",
       " 'peck',\n",
       " 'pickl',\n",
       " 'pepper',\n",
       " 'peter',\n",
       " 'piper',\n",
       " 'pick']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove special characters\n",
    "# remove stop words\n",
    "# stem words\n",
    "# normalize text (lowercase)\n",
    "\n",
    "# download stopwords and punkt\n",
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words( 'english' ) + list(punctuation)\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "text = text.lower()\n",
    "words = nltk.word_tokenize(text)\n",
    "words = [stemmer.stem(w) for w in words if w not in stopwords]\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'peter': 2,\n",
       "         'piper': 2,\n",
       "         'pick': 2,\n",
       "         'peck': 2,\n",
       "         'pickl': 2,\n",
       "         'pepper': 2})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Classifier\n",
    "\n",
    "To classify Positive vs Negative sentiment given a Yelp review we use the word frequency thinking some words are used more than others when relating sentiment. Using just word frequency has a drawback, namely, common words don't convery much meaning but would get high weights of importance with just word frequency. **Solution:** Divide the word frequency by the number of document the word appears in. This is called *Term Frequency Inverse Document Frequency** or **TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loved</th>\n",
       "      <th>loved place</th>\n",
       "      <th>place</th>\n",
       "      <th>wow</th>\n",
       "      <th>wow loved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>0.447214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loved  loved place     place       wow  wow loved\n",
       "0  0.447214     0.447214  0.447214  0.447214   0.447214"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# This vectorizer breaks text into single words and bi-grams\n",
    "# and then calculates the TF-IDF representation\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), lowercase=True, stop_words=stopwords)\n",
    "\n",
    "vectors = vectorizer.fit_transform(data[\"text\"][:1])\n",
    "pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>10</th>\n",
       "      <th>10 minutes</th>\n",
       "      <th>10 times</th>\n",
       "      <th>100</th>\n",
       "      <th>100 recommended</th>\n",
       "      <th>100 times</th>\n",
       "      <th>11</th>\n",
       "      <th>11 99</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>yum</th>\n",
       "      <th>yum sauce</th>\n",
       "      <th>yum yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yummy christmas</th>\n",
       "      <th>yummy try</th>\n",
       "      <th>yummy tummy</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero stars</th>\n",
       "      <th>zero taste</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6074 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00   10  10 minutes  10 times  100  100 recommended  100 times   11  \\\n",
       "0  0.0  0.0         0.0       0.0  0.0              0.0        0.0  0.0   \n",
       "1  0.0  0.0         0.0       0.0  0.0              0.0        0.0  0.0   \n",
       "2  0.0  0.0         0.0       0.0  0.0              0.0        0.0  0.0   \n",
       "3  0.0  0.0         0.0       0.0  0.0              0.0        0.0  0.0   \n",
       "4  0.0  0.0         0.0       0.0  0.0              0.0        0.0  0.0   \n",
       "\n",
       "   11 99   12  ...  yum  yum sauce  yum yum  yummy  yummy christmas  \\\n",
       "0    0.0  0.0  ...  0.0        0.0      0.0    0.0              0.0   \n",
       "1    0.0  0.0  ...  0.0        0.0      0.0    0.0              0.0   \n",
       "2    0.0  0.0  ...  0.0        0.0      0.0    0.0              0.0   \n",
       "3    0.0  0.0  ...  0.0        0.0      0.0    0.0              0.0   \n",
       "4    0.0  0.0  ...  0.0        0.0      0.0    0.0              0.0   \n",
       "\n",
       "   yummy try  yummy tummy  zero  zero stars  zero taste  \n",
       "0        0.0          0.0   0.0         0.0         0.0  \n",
       "1        0.0          0.0   0.0         0.0         0.0  \n",
       "2        0.0          0.0   0.0         0.0         0.0  \n",
       "3        0.0          0.0   0.0         0.0         0.0  \n",
       "4        0.0          0.0   0.0         0.0         0.0  \n",
       "\n",
       "[5 rows x 6074 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = vectorizer.fit_transform(data[\"text\"])\n",
    "pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "\n",
    "punc_list = list(punctuation)\n",
    "def special_remove(word):\n",
    "    if len(word)>2:\n",
    "        return False\n",
    "    for c in word:\n",
    "        if c in punc_list:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# custom function that overrides default token generation\n",
    "def custom_tokenizer(text):\n",
    "    text = text.lower()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    words = [stemmer.stem(w) for w in words if w not in stopwords+[\"...\"]]\n",
    "    # further remove woords with a special char\n",
    "    words = [w for w in words if not special_remove(w)]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'ll</th>\n",
       "      <th>'ll back</th>\n",
       "      <th>'ll definit</th>\n",
       "      <th>'ll done</th>\n",
       "      <th>'ll go</th>\n",
       "      <th>'ll hit</th>\n",
       "      <th>'ll impress</th>\n",
       "      <th>'ll leav</th>\n",
       "      <th>'ll never</th>\n",
       "      <th>'ll regular</th>\n",
       "      <th>...</th>\n",
       "      <th>yum</th>\n",
       "      <th>yum sauc</th>\n",
       "      <th>yum yum</th>\n",
       "      <th>yummi</th>\n",
       "      <th>yummi christma</th>\n",
       "      <th>yummi tri</th>\n",
       "      <th>yummi tummi</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero star</th>\n",
       "      <th>zero tast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5831 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   'll  'll back  'll definit  'll done  'll go  'll hit  'll impress  \\\n",
       "0  0.0       0.0          0.0       0.0     0.0      0.0          0.0   \n",
       "1  0.0       0.0          0.0       0.0     0.0      0.0          0.0   \n",
       "2  0.0       0.0          0.0       0.0     0.0      0.0          0.0   \n",
       "3  0.0       0.0          0.0       0.0     0.0      0.0          0.0   \n",
       "4  0.0       0.0          0.0       0.0     0.0      0.0          0.0   \n",
       "\n",
       "   'll leav  'll never  'll regular  ...  yum  yum sauc  yum yum  yummi  \\\n",
       "0       0.0        0.0          0.0  ...  0.0       0.0      0.0    0.0   \n",
       "1       0.0        0.0          0.0  ...  0.0       0.0      0.0    0.0   \n",
       "2       0.0        0.0          0.0  ...  0.0       0.0      0.0    0.0   \n",
       "3       0.0        0.0          0.0  ...  0.0       0.0      0.0    0.0   \n",
       "4       0.0        0.0          0.0  ...  0.0       0.0      0.0    0.0   \n",
       "\n",
       "   yummi christma  yummi tri  yummi tummi  zero  zero star  zero tast  \n",
       "0             0.0        0.0          0.0   0.0        0.0        0.0  \n",
       "1             0.0        0.0          0.0   0.0        0.0        0.0  \n",
       "2             0.0        0.0          0.0   0.0        0.0        0.0  \n",
       "3             0.0        0.0          0.0   0.0        0.0        0.0  \n",
       "4             0.0        0.0          0.0   0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 5831 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), tokenizer=custom_tokenizer)\n",
    "\n",
    "vectors = vectorizer.fit_transform(data[\"text\"])\n",
    "pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Model\n",
    "\n",
    "**TFIDF** is used to convert text into numeric values. A model must still take those numbers to compute probabilities of Positive or Negative sentiment. A Naive Bayes model computes a probability by\n",
    "    * Assuming features are independent (words and bi-grams)\n",
    "    * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/PythonData/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()\n",
    "X = vectors.toarray()\n",
    "y = data[[\"class\"]].values\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative'], dtype='<U8')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['negative']], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual prediction\n",
       "0  positive   positive\n",
       "1  negative   negative\n",
       "2  negative   negative\n",
       "3  positive   positive\n",
       "4  positive   positive"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"actual\": y.reshape(-1), \"prediction\": model.predict(X)}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_preds = sum([\n",
    "    actual == predict\n",
    "    for actual, predict in zip(y.reshape(-1), model.predict(X))\n",
    "])\n",
    "\n",
    "total_preds = len(y.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.988"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_preds / total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
