{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Python NaturalLanguageToolKit (NLTK) \n",
    "\n",
    "is a set of modules and corpora enabling the reader to do natural langauge processing against corpora of one or more texts. It goes beyond text minnig and provides tools to do machine learning, but this Notebook barely scratches that surface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install NLTK & Download data\n",
    "\n",
    "* pip install nltk -- install nltk in the correct virtual environment\n",
    "* import nltk\n",
    "* nltk.download() -- pops up a GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "# nltk.download()\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent1: Call me Ishmael .\n",
      "sent2: The family of Dashwood had long been settled in Sussex .\n",
      "sent3: In the beginning God created the heaven and the earth .\n",
      "sent4: Fellow - Citizens of the Senate and of the House of Representatives :\n",
      "sent5: I have a problem with people PMing me to lol JOIN\n",
      "sent6: SCENE 1 : [ wind ] [ clop clop clop ] KING ARTHUR : Whoa there !\n",
      "sent7: Pierre Vinken , 61 years old , will join the board as a nonexecutive director Nov. 29 .\n",
      "sent8: 25 SEXY MALE , seeks attrac older single lady , for discreet encounters .\n",
      "sent9: THE suburb of Saffron Park lay on the sunset side of London , as red and ragged as a cloud of sunset .\n"
     ]
    }
   ],
   "source": [
    "sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outline\n",
    "\n",
    "- Text similarity and concordance\n",
    "\n",
    "- Plot word location (dispersion plot)\n",
    "\n",
    "- Plot frequency distribtions\n",
    "\n",
    "- NGrams\n",
    "\n",
    "- Word Tokenize\n",
    "\n",
    "- Sentence Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The cat is green\n",
    "N-Gram\n",
    "\n",
    "Bi-Gram (N=2)\n",
    "[(The, cat), (cat,is), (is,green)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concordance\n",
    "A concordance permits us to see words in context. For example, we saw that monstrous occurred in contexts such as the size and picture of a whale. What other words appear in a similar range of contexts? We can find out by appending the term similar to the name of the text in question, then inserting the relevant word in parentheses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: The Book of Genesis>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(text1.concordance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 25 matches:\n",
      "ay when they were created . And Adam lived an hundred and thirty years , and be\n",
      "ughters : And all the days that Adam lived were nine hundred and thirty yea and\n",
      "nd thirty yea and he died . And Seth lived an hundred and five years , and bega\n",
      "ve years , and begat Enos : And Seth lived after he begat Enos eight hundred an\n",
      "welve years : and he died . And Enos lived ninety years , and begat Cainan : An\n",
      " years , and begat Cainan : And Enos lived after he begat Cainan eight hundred \n",
      "ive years : and he died . And Cainan lived seventy years and begat Mahalaleel :\n",
      "rs and begat Mahalaleel : And Cainan lived after he begat Mahalaleel eight hund\n",
      "years : and he died . And Mahalaleel lived sixty and five years , and begat Jar\n",
      "s , and begat Jared : And Mahalaleel lived after he begat Jared eight hundred a\n",
      "and five yea and he died . And Jared lived an hundred sixty and two years , and\n",
      "o years , and he begat Eno And Jared lived after he begat Enoch eight hundred y\n",
      " and two yea and he died . And Enoch lived sixty and five years , and begat Met\n",
      " ; for God took him . And Methuselah lived an hundred eighty and seven years , \n",
      " , and begat Lamech . And Methuselah lived after he begat Lamech seven hundred \n",
      "nd nine yea and he died . And Lamech lived an hundred eighty and two years , an\n",
      "ch the LORD hath cursed . And Lamech lived after he begat Noah five hundred nin\n",
      "naan shall be his servant . And Noah lived after the flood three hundred and fi\n",
      "xad two years after the flo And Shem lived after he begat Arphaxad five hundred\n",
      "at sons and daughters . And Arphaxad lived five and thirty years , and begat Sa\n",
      "ars , and begat Salah : And Arphaxad lived after he begat Salah four hundred an\n",
      "begat sons and daughters . And Salah lived thirty years , and begat Eber : And \n",
      "y years , and begat Eber : And Salah lived after he begat Eber four hundred and\n",
      " begat sons and daughters . And Eber lived four and thirty years , and begat Pe\n",
      "y years , and begat Peleg : And Eber lived after he begat Peleg four hundred an\n"
     ]
    }
   ],
   "source": [
    "#text1.concordance(\"monstrous\")\n",
    "text3.concordance(\"lived\") # genesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n"
     ]
    }
   ],
   "source": [
    "# help(text1.similar)\n",
    "# text1.similar(\"monstrous\")\n",
    "text2.similar(\"monstrous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term common_contexts allows us to examine just the contexts that are shared by two or more words, such as monstrous and very. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_pretty am_glad a_lucky is_pretty be_glad\n"
     ]
    }
   ],
   "source": [
    "text2.common_contexts([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare similar words\n",
      "word =  monstrous  in  <Text: Moby Dick by Herman Melville 1851>\n",
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n",
      "word =  very  in  <Text: Moby Dick by Herman Melville 1851>\n",
      "a same so last first pretty the too other only as one great white\n",
      "strange rather next entire now his\n",
      "word =  monstrous  in  <Text: Sense and Sensibility by Jane Austen 1811>\n",
      "very so exceedingly heartily a as good great extremely remarkably\n",
      "sweet vast amazingly\n",
      "word =  very  in  <Text: Sense and Sensibility by Jane Austen 1811>\n",
      "so as too a not monstrous the was more most how last exceedingly her\n",
      "it only first will perfectly cottage\n",
      "text2.common_contexts: \n",
      "a_pretty am_glad a_lucky is_pretty be_glad\n"
     ]
    }
   ],
   "source": [
    "def compare_words(*words):\n",
    "    print(\"Compare similar words\")\n",
    "    for word in words:\n",
    "        print('word = ', word, ' in ', text1)\n",
    "        text1.similar(word)\n",
    "    for word in words:\n",
    "        print('word = ', word, ' in ', text2)\n",
    "        text2.similar(word)\n",
    "    print(\"text2.common_contexts: \")\n",
    "    text2.common_contexts(list(words))\n",
    "compare_words(\"monstrous\", \"very\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is one thing to automatically detect that a particular word occurs in a text, and to display some words that appear in the same context. However, we can also determine the location of a word in the text: how many words from the beginning it appears. This positional information can be displayed using a dispersion plot. Each stripe represents an instance of a word, and each row represents the entire text. In 1.2 we see some striking patterns of word usage over the last 220 years (in an artificial text constructed by joining the texts of the Inaugural Address Corpus end-to-end). You can produce this plot as shown below. You might like to try more words (e.g., liberty, constitution), and different texts. Can you predict the dispersion of a word before you view it? As before, take care to get the quotes, commas, brackets and parentheses exactly right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2.dispersion_plot([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duties\", \"America\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text3)\n",
    "# sorted(set(text3))\n",
    "# text3.count(\"smote\")\n",
    "# 100 * text3.count('smote') / len(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(set(text)) / len(text)\n",
    "\n",
    "def percentage(count, total):\n",
    "    return 100 * count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_diversity(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage(text3.count(\"God\"), len(text3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1 = FreqDist(text1)\n",
    "print(fdist1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1['whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist1.plot(50, cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot length of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = FreqDist(len(w) for w in text1)\n",
    "fdist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist.plot(50, cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-grained Selection of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist5 = FreqDist(text5)\n",
    "sorted(w for w in set(text5) if len(w) > 7 and fdist5[w] > 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations and Bigrams\n",
    "\n",
    "A collocation is a sequence of words that occur together unusually often. Thus red wine is a collocation, whereas the wine is not. A characteristic of collocations is that they are resistant to substitution with words that have similar senses; for example, maroon wine sounds definitely odd.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bigrams(['more', 'is', 'said', 'than', 'done']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1.collocations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources for further learning\n",
    "Main NLTK Python website:  https://www.nltk.org/\n",
    "\n",
    "NLTK Book: http://www.nltk.org/book/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
