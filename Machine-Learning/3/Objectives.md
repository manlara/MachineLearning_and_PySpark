Todays Objectives

* Cross Validation Techniques

    1) K-Fold Cross validation
    https://en.wikipedia.org/wiki/Cross-validation_(statistics)

* Evaluation metrics for classification
    
    1) Accuracy (Correct / Total)

    2) True Positive Rate (TP)

    3) False Positive Rate (FP)

    4) True Negative Rate (TN)

    5) False Negative Rate (FN)

    6) Precision
    Sensitive to False Positive rates
    Example: Cancer diagnosise but had No Cancer
    P = TP / (FP + TP)

    7) Recall
    Sensitive to False Negative rates
    Example: No Cancer diagnosis but had Cancer
    R = TP / (FN + TP)

    8) F1
    Harmonic mean of precsion and recall
    1/F1 = 1/2(1/P + 1/R)
    F1 = 2 P*R / (R + P)

* Classification ML models

    2) Logistic Regression 

    2) Decision Trees

    3) K Nearest Neighbor

    4) Support Vector Machine

* Clustering ML model
    
    1) K Means

* Working with Imbalanced datasets

* Resources

    1) Decision Trees and Random Forest
    https://www.datacamp.com/community/tutorials/decision-trees-R
    https://victorzhou.com/blog/    intro-to-random-forests/
    https://victorzhou.com/blog/information-gain/

    2) K Nearest Neighbor
    Details of KNN algorithm with code walkthrough in Python
    https://youtu.be/AoeEHqVSNOw?t=197

    3) Support Vector Machine
    Applications
    https://youtu.be/N1vOgolbjSc?t=1084
    https://youtu.be/N1vOgolbjSc?t=1106
    https://youtu.be/N1vOgolbjSc?t=1159

    4) K Means Cluster
    Understanding K means algorithm and choosing K
    https://www.datascience.com/blog/k-means-clustering

    5) Precision & Recall
    https://en.wikipedia.org/wiki/Precision_and_recall

    6) F1 Score
    https://en.wikipedia.org/wiki/F1_score
